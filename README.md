# Beyond Seq2Seq, A deep Dive in a low scale implementation of Google Neural Machine Translation:

##### Yassin Bahid


## Introduction:

As Seen in my previous report, Seq2Seq offers a great first step in Deepl learning's solution to language translation. However, it stays limitted. Yonghui Wu. et. al 's solution is presented in their 2016 paper: Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation. In this paper they offer an end-to-end translation recurrent network. While the original architechture stays expensive, we offer certain modifications to ease the training on smaller machine.





Chen, H., Zhuang, F., Xiao, L., Ma, L., Liu, H., Zhang, R., Jiang, H., & He, Q. (2021). AMA-GCN: Adaptive Multi-layer Aggregation Graph Convolutional Network for Disease Prediction (Version 1). arXiv. https://doi.org/10.48550/ARXIV.2106.08732
